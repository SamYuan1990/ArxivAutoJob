arxiv_id,date,title,position_index,initiative_index,position_index_comments,Unnamed: 6,initiative_index_comments,downloaded
2201.11903,2022-01-28,Chain-of-Thought Prompting Elicits Reasoning \\ in Large Language Models,prompt,hard code style,"The paper focuses on chain-of-thought prompting, which is a prompting technique that enhances reasoning in large language models without requiring training or fine-tuning. It falls under the 'prompt' category as it involves improving single-agent reasoning through prompt engineering rather than multi-agent systems, external data management, or model training.",,"Chain-of-thought prompting requires manually crafting prompts with exemplars that include intermediate reasoning steps. This is a hard-coded approach where humans design the prompting structure and provide specific reasoning demonstrations, rather than automated adjustment mechanisms or code implementations.",True
2205.11916,2022-05-24,Formatting Instructions For NeurIPS 2022,prompt,hard code style,"The paper focuses on prompt engineering techniques for eliciting reasoning capabilities from pretrained large language models. It introduces Zero-shot-CoT, which uses a simple prompt template 'Let's think step by step' to facilitate step-by-step reasoning without requiring task-specific examples or fine-tuning.",,"The approach uses a fixed, manually designed prompt template ('Let's think step by step') that is applied uniformly across all tasks without modification. The prompting strategy is hard-coded and not automatically adjusted based on metrics or left to the LLM to determine.",True
2305.10601,2023-05-17,Deliberate Search in Tree of Thoughts,prompt , auto adjust leave to LLM ,"The paper introduces Tree of Thoughts (ToT), a framework that enhances language model inference by enabling exploration over coherent units of text ('thoughts') as intermediate steps toward problem solving. This involves considering multiple reasoning paths, self-evaluating choices, and using search algorithms like BFS or DFS. The framework operates during inference and involves prompting the LM to generate and evaluate thoughts, as well as managing the exploration of different reasoning paths, which aligns with prompt and external data management aspects.",,"The framework uses language models to self-evaluate the progress of intermediate thoughts and generate diverse reasoning paths through prompting. The search algorithms (e.g., BFS, DFS) are hard-coded to systematically explore the tree of thoughts, but the generation and evaluation of thoughts are left to the LLM, indicating a combination of hard-coded and LLM-driven adjustments.",True
2210.03629,2022-10-06,: Synergizing Reasoning and Acting in Language Models,prompt,auto adjust leave to LLM,"This paper focuses on synergizing reasoning and acting in language models, which involves integrating reasoning processes with action execution. This aligns with prompt engineering approaches where specific prompting techniques (like ReAct) are used to guide LLMs to alternate between reasoning traces and task-specific actions.",,"The approach described involves designing prompting strategies that enable language models to dynamically alternate between reasoning and acting. This represents an auto-adjust mechanism where the LLM itself determines when to reason and when to act based on the context, rather than being hard-coded or requiring explicit code implementations for each transition.",True
2311.07076,2023-11-13,{On the Discussion of Large Language Models:,prompt,auto adjust according to specific metric,"The paper discusses both prompt engineering (Chain-of-Thought, In-Context Learning, emotional prompt) and multi-agent discussion mechanisms (Multi-Agent Debate, MAD, ReConcile, Conquer-and-Merge Discussion). It systematically analyzes the interplay between prompt decorators and discussion mechanisms, justifying multi-agent discussions from symmetry perspectives.",,"The paper examines both fixed pipelines (Chain-of-Thoughts Self-Consistency) and adaptive pipelines (Tree-of-Thoughts, Graph-of-Thoughts, Cumulative Reasoning). It also discusses emergent pipelines where reasoning processes self-organize through multi-agent interactions without predefined structures, and proposes a scalable mechanism (CMD) with simple prompts.",True
2410.02953,2024-10-03,Unlocking Structured Thinking in Language Models with Cognitive Prompting,prompt,hard code style_auto adjust leave to LLM,"The paper focuses on cognitive prompting methods that guide LLMs through structured reasoning operations. This involves designing specific prompt structures and sequences to enhance problem-solving capabilities, which falls under prompt engineering.",,"The paper introduces three variants of cognitive prompting: deterministic sequence (hard-coded structure), self-adaptive variant (LLM dynamically selects operations), and hybrid variant (combines generated solutions as few-shot examples). This spans from hard-coded approaches to auto-adjustment by LLM.",True
2311.06318,2023-11-10,Knowledge-Augmented-Large-Language-Models-for-Personalized-Contextual-Query-Suggestion,external data mgr,hard code style_code impls,"The paper focuses on augmenting LLM prompts with user-specific context from search histories and knowledge graphs, which falls under external data management (RAG-like approach) rather than training, fine-tuning, or multi-agent systems.",,"The system constructs and leverages a pre-defined, structured knowledge store based on user interactions and public knowledge graphs, indicating a hard-coded or code-implemented approach rather than dynamic LLM-driven adjustments.",True
2012.15723,2020-12-31,Making Pre-trained Language Models Better Few-shot Learners,prompt,code impls_auto adjust according to specific metric,"This paper focuses on improving few-shot learning capabilities of pre-trained language models, which involves adapting existing models to new tasks with minimal examples. This falls under the prompt category as it deals with how to effectively use and adapt pre-trained models through prompting strategies rather than retraining the model architecture or implementing external data management systems.",,"The paper proposes methods to enhance few-shot learning, which typically involves systematic approaches to prompt construction and optimization. This would involve code implementations and potentially auto-adjustment strategies to optimize prompt effectiveness, though the specific implementation details would determine the exact approach.",True
2203.11171,2022-03-21,Self-Consistency Improves Chain of Thought Reasoning in Language Models,prompt,auto adjust according to specific metric,"The paper focuses on a decoding strategy called self-consistency that works with chain-of-thought prompting. This involves sampling multiple reasoning paths from a pre-trained language model and selecting the most consistent answer, which falls under prompt engineering techniques rather than model training or external data management.",,The self-consistency method involves automatically sampling multiple reasoning paths from the language model and then automatically selecting the most consistent answer through marginalization. This represents an auto-adjust approach based on consistency metrics rather than hard-coded rules or manual implementation.,True
2005.11401,2020-05-22,Retrieval-Augmented Generation (Title needed),external data mgr,code impls,"The paper describes Retrieval-Augmented Generation (RAG), which combines a pre-trained retriever (query encoder + document index) with a pre-trained seq2seq generator. This architecture uses external document retrieval to augment generation, falling under the 'external data mgr' category as it involves retrieving and using external documents during the generation process.",,"The approach involves fine-tuning the retriever and generator end-to-end, indicating that the retrieval and generation components are optimized together through training. This suggests a 'code impls' approach where the system is implemented and trained with specific parameters, rather than being hard-coded or left entirely to LLM auto-adjustment.",True
2504.16053,2025-04-22,LongMamba: Enhancing Long Context Understanding for Mamba Models via Training-Free Receptive Field Alignment,post training,code impls,"The paper focuses on enhancing long context understanding for Mamba models through receptive field alignment, which involves adjusting the model's ability to process extended sequences without retraining. This aligns with post-training techniques that modify model behavior after initial training.",,"The method is described as training-free and involves adjustments to the receptive field, suggesting it is implemented through code modifications rather than manual hard-coding or LLM-driven automation. It likely uses specific algorithms or code implementations to achieve the alignment.",True
2307.02486,2023-07-05,{,training,hard code style_code impls,"This paper introduces LongNet, a Transformer variant that scales sequence length to over 1 billion tokens through dilated attention. The work focuses on architectural modifications to the Transformer model itself, specifically replacing standard attention with dilated attention to achieve linear computation complexity. This represents fundamental changes to the model architecture and training process.",,"The paper presents a hard-coded architectural solution with specific implementation details. The dilated attention mechanism has a fixed exponential expansion pattern for the attentive field as distance grows. The approach includes distributed training algorithms and can be integrated with existing Transformer optimizations, representing a systematic engineering implementation rather than adaptive or LLM-driven adjustments.",True
2205.14135,2022-05-27,: Fast and Memory-Efficient Exact Attention with IO-Awareness,training,code impls,"This paper focuses on optimizing the attention mechanism in transformer architectures, which is a core component of the training process for models like RNNs and transformers. The work specifically addresses computational efficiency and memory management during the attention computation phase, which occurs during model training.",,"The paper proposes code implementations and algorithmic optimizations for attention computation, including techniques like kernel fusion, tiling strategies, and memory-aware scheduling. These are systematic code-level improvements rather than hard-coded solutions or auto-adjusting mechanisms.",True
2310.01889,2023-10-03,Ring Attention with Blockwise \\ Transformers for Near-Infinite Context,training,hard code style_code impls,"The paper focuses on architectural improvements to Transformers to handle long sequences through distributed computation across multiple devices. This involves blockwise computation of self-attention and feedforward layers, which is a fundamental architectural modification to the training process.",,The approach involves implementing a specific computational architecture (Ring Attention with Blockwise Transformers) with code implementations that distribute computation across devices in a ring topology. The method is hard-coded in its distribution pattern and communication scheme.,True
2309.00071,2023-08-31,YaRN: Efficient Context Window Extension of Large Language Models,post training_external data mgr,code impls_auto adjust according to specific metric,"The paper focuses on extending the context window of pre-trained LLMs through modifications to Rotary Position Embeddings (RoPE) and fine-tuning, which falls under post-training methods. It also involves external data management aspects through position encoding schemes that handle longer sequences.",,"The method involves code implementations for modifying RoPE (specifically through interpolation techniques like NTK-aware, Dynamic NTK, NTK-by-parts, and YaRN) and fine-tuning processes to achieve context window extension. The adjustments are based on specific metrics and computational efficiency considerations.",True
2404.07143,2024-04-10,Leave No Context Behind: \\ Efficient Infinite Context Transformers with Infini-attention,training,code impls,"The paper introduces Infini-attention, which incorporates a compressive memory into the vanilla attention mechanism of Transformers. This involves modifying the core attention architecture to handle long-term dependencies through memory consolidation and retrieval, which falls under training as it requires architectural changes and training processes.",,"The approach involves architectural modifications to the Transformer attention mechanism (Infini-attention) with compressive memory, which is implemented through code changes and training procedures. The memory update and retrieval are part of the model's fixed design, not dynamically adjusted by the LLM itself.",True
2309.17453,2023-09-29,Efficient Streaming Language Models \\ with Attention Sinks,training,code impls,"This paper focuses on streaming language models that maintain performance during extended sequence generation. The core contribution involves modifying the attention mechanism to handle long sequences efficiently, which falls under architectural improvements to the transformer model. This represents training-level modifications to the model architecture itself.",,The paper proposes specific architectural modifications and algorithms (like attention sinks) that are implemented through code changes to the model architecture. These are hard-coded solutions designed to improve streaming performance rather than being automatically adjusted or left to the LLM.,True
2402.04617,2024-02-07,{,external data mgr,hard code style_code impls,"The paper introduces InfLLM, a training-free memory-based method that stores distant contexts into additional memory units and uses an efficient lookup mechanism for attention computation. This approach enables LLMs to process long sequences without any training or fine-tuning, which aligns with external data management as it involves storing and retrieving context from memory units rather than modifying the model architecture or training process.",,The method is implemented as code that automatically manages memory units and performs lookup operations for attention computation. It operates in a hard-coded style where the memory storage and retrieval mechanisms are predefined and executed without LLM-driven adjustments or automatic metric-based tuning.,True
2303.17651,2023-03-30,:\ Refinement with Self-Feedback,post training,auto adjust according to specific metric_auto adjust leave to LLM,The paper title 'Refinement with Self-Feedback' suggests a process where a system iteratively improves its own outputs through self-generated feedback. This aligns with post-training refinement techniques where models enhance their initial responses through iterative self-correction mechanisms.,,"The concept of 'Self-Feedback' implies an automated adjustment process where the system generates its own feedback and uses it for refinement. This suggests an auto-adjust mechanism based on self-evaluation metrics or criteria, rather than hard-coded rules or manual intervention.",True
2303.11366,2023-03-20,Reflexion: Language Agents with \\ Verbal Reinforcement Learning,external data mgr,auto adjust according to specific metric,"The paper focuses on a framework where language agents learn from trial-and-error through linguistic feedback stored in episodic memory, without updating model weights. This involves maintaining reflective text in memory buffers to improve decision-making in subsequent trials, which aligns with external data management for storing and utilizing past experiences.",,"Reflexion agents use verbal feedback (e.g., binary environment feedback, pre-defined heuristics, or self-evaluation via LLMs) to generate reflective summaries. The adjustment of behavior is based on these summaries stored in memory, allowing the agent to auto-adjust according to specific metrics (e.g., task success) without manual intervention, leveraging the LLM's capabilities for self-reflection.",True
2305.09645,2023-05-16,StructGPT: A General Framework for Large Language Model\\ to Reason over Structured Data,external data mgr_prompt,code impls,"The paper develops a framework (StructGPT) that uses specialized interfaces to access structured data and an iterative procedure for LLMs to reason over this data. This involves tool augmentation for data access and reasoning, which aligns with external data management (interfaces for structured data access) and prompt-based approaches (the iterative reading-then-reasoning procedure leverages LLMs for reasoning without modifying the model itself).",,"The framework involves constructing specialized interfaces for data access and an iterative procedure (invoking-linearization-generation) that is implemented as code to guide the LLM's reasoning process. The approach is code-implemented to structure the interaction between the LLM and the interfaces, rather than being hard-coded or fully automated by the LLM alone.",True
2105.02605,2021-05-06,GraphFormers: GNN-nested Transformers for Representation Learning on Textual Graph,training,hard code style_code impls,"The paper proposes GraphFormers, which involves training a novel neural network architecture that combines GNN components with transformer layers. This represents model training rather than post-training, prompt engineering, external data management, or multiple agents.",,The paper describes a specific neural network architecture implementation (GraphFormers) with code implementation details and a progressive training strategy. The model architecture and training process are hard-coded implementations rather than auto-adjusting systems.,True
2201.0886,2022-01-03,,,,"This paper focuses on mathematical analysis of dynamical systems, specifically studying strange attractors and chaos in periodically perturbed differential equations. It develops theoretical frameworks and mathematical proofs for understanding complex dynamical behaviors, which falls outside the defined categories of training, post-training, prompt, external data management, or multiple agents.",,"The paper presents mathematical theory development with rigorous proofs and analytical methods. It involves mathematical modeling, theoretical analysis, and proof techniques rather than computational implementations or automated adjustments. The approach is fundamentally mathematical and theoretical in nature.",True
2503.09567,2025-03-12,{-5pt,training_prompt_external data mgr,code impls_auto adjust according to specific metric,"This paper is a survey that analyzes and categorizes reasoning paradigms in large language models, specifically focusing on Long Chain-of-Thought characteristics. It discusses training approaches that enable Long CoT reasoning, prompt engineering techniques for reasoning, and external data management aspects related to knowledge frameworks.",,The paper discusses reasoning approaches that can be implemented through code implementations and also mentions auto-adjustment capabilities where models can dynamically adapt their reasoning processes based on specific metrics and requirements.,True
2012.15723,2020-12-31,,,,,,,True
